{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G22TLMXlIHA_"
      },
      "source": [
        "# Neural Network Example\n",
        "\n",
        "Build a 2-hidden layers fully connected neural network (a.k.a multilayer perceptron) with TensorFlow v2.\n",
        "\n",
        "This example is using a low-level approach to better understand all mechanics behind building neural networks and the training process.\n",
        "\n",
        "- Author: Aymeric Damien\n",
        "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PRQTjxvIHBF"
      },
      "source": [
        "## Neural Network Overview\n",
        "\n",
        "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/>\n",
        "\n",
        "## MNIST Dataset Overview\n",
        "\n",
        "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 255. \n",
        "\n",
        "In this example, each image will be converted to float32, normalized to [0, 1] and flattened to a 1-D array of 784 features (28*28).\n",
        "\n",
        "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
        "\n",
        "More info: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "59s8KrWHIHBH"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "import numpy as np\n",
        "import pandas as pd        # For loading and processing the dataset.\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Mau94epIHBK"
      },
      "outputs": [],
      "source": [
        "# MNIST dataset parameters.\n",
        "num_classes = 2 # total classes (0-9 digits).\n",
        "num_features = 14 # data features (img shape: 28*28).\n",
        "\n",
        "# Training parameters.\n",
        "learning_rate = 0.1\n",
        "training_steps = 2000\n",
        "batch_size = 256\n",
        "display_step = 100\n",
        "\n",
        "# Network parameters.\n",
        "n_hidden_1 = 128 # 1st layer number of neurons.\n",
        "n_hidden_2 = 256 # 2nd layer number of neurons."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we convert the Pandas dataframe to a NumPy array, and split it into a training and test set\n",
        "# Read the CSV input file and show first 5 rows\n",
        "df_train = pd.read_csv('/content/task1_dataset_train.csv')\n",
        "df_train.head(5)\n",
        "X = df_train.drop('y', axis=1).values\n",
        "y = df_train['y'].values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "6tEfNRlpIb1i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lOK4izaRIHBL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eQaYkptyIHBN"
      },
      "outputs": [],
      "source": [
        "# Use tf.data API to shuffle and batch data.\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TwEMwrPpI3eQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dgO_TIYLIHBO"
      },
      "outputs": [],
      "source": [
        "# Create TF Model.\n",
        "class NeuralNet(Model):\n",
        "    # Set layers.\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        # First fully-connected hidden layer.\n",
        "        self.fc1 = layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
        "        # First fully-connected hidden layer.\n",
        "        self.fc2 = layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
        "        # Second fully-connecter hidden layer.\n",
        "        self.out = layers.Dense(num_classes)\n",
        "\n",
        "    # Set forward pass.\n",
        "    def call(self, x, is_training=False):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.out(x)\n",
        "        if not is_training:\n",
        "            # tf cross entropy expect logits without softmax, so only\n",
        "            # apply softmax when not training.\n",
        "            x = tf.nn.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Build neural network model.\n",
        "neural_net = NeuralNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bIikRNlpIHBP"
      },
      "outputs": [],
      "source": [
        "# Cross-Entropy Loss.\n",
        "# Note that this will apply 'softmax' to the logits.\n",
        "def cross_entropy_loss(x, y):\n",
        "    # Convert labels to int 64 for tf cross-entropy function.\n",
        "    y = tf.cast(y, tf.int64)\n",
        "    # Apply softmax to logits and compute cross-entropy.\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
        "    # Average loss across the batch.\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# Accuracy metric.\n",
        "def accuracy(y_pred, y_true):\n",
        "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
        "\n",
        "# Stochastic gradient descent optimizer.\n",
        "optimizer = tf.optimizers.SGD(learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pWqrh5yfIHBQ"
      },
      "outputs": [],
      "source": [
        "# Optimization process. \n",
        "def run_optimization(x, y):\n",
        "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
        "    with tf.GradientTape() as g:\n",
        "        # Forward pass.\n",
        "        pred = neural_net(x, is_training=True)\n",
        "        # Compute loss.\n",
        "        loss = cross_entropy_loss(pred, y)\n",
        "        \n",
        "    # Variables to update, i.e. trainable variables.\n",
        "    trainable_variables = neural_net.trainable_variables\n",
        "\n",
        "    # Compute gradients.\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "    \n",
        "    # Update W and b following gradients.\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mn-AaLiOIHBR",
        "outputId": "cd9214f6-3b6f-40e2-880e-f789de36610f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 100, loss: 0.486165, accuracy: 0.769531\n",
            "step: 200, loss: 0.520279, accuracy: 0.750000\n",
            "step: 300, loss: 0.530207, accuracy: 0.714844\n",
            "step: 400, loss: 0.465484, accuracy: 0.789062\n",
            "step: 500, loss: 0.461355, accuracy: 0.792969\n",
            "step: 600, loss: 0.475713, accuracy: 0.789062\n",
            "step: 700, loss: 0.436438, accuracy: 0.804688\n",
            "step: 800, loss: 0.450595, accuracy: 0.757812\n",
            "step: 900, loss: 0.489487, accuracy: 0.765625\n",
            "step: 1000, loss: 0.461266, accuracy: 0.750000\n",
            "step: 1100, loss: 0.420362, accuracy: 0.804688\n",
            "step: 1200, loss: 0.434839, accuracy: 0.812500\n",
            "step: 1300, loss: 0.410994, accuracy: 0.781250\n",
            "step: 1400, loss: 0.398383, accuracy: 0.800781\n",
            "step: 1500, loss: 0.347369, accuracy: 0.851562\n",
            "step: 1600, loss: 0.385559, accuracy: 0.796875\n",
            "step: 1700, loss: 0.425821, accuracy: 0.789062\n",
            "step: 1800, loss: 0.377654, accuracy: 0.824219\n",
            "step: 1900, loss: 0.424663, accuracy: 0.769531\n",
            "step: 2000, loss: 0.415788, accuracy: 0.796875\n"
          ]
        }
      ],
      "source": [
        "# Run training for the given number of steps.\n",
        "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
        "    # Run the optimization to update W and b values.\n",
        "    run_optimization(batch_x, batch_y)\n",
        "    \n",
        "    if step % display_step == 0:\n",
        "        pred = neural_net(batch_x, is_training=True)\n",
        "        loss = cross_entropy_loss(pred, batch_y)\n",
        "        acc = accuracy(pred, batch_y)\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3xqjzrGJIHBT",
        "outputId": "136c8366-9463-4ae7-faf3-4cc6da0cd10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.807301\n"
          ]
        }
      ],
      "source": [
        "# Test model on validation set.\n",
        "pred = neural_net(X_test, is_training=False)\n",
        "print(\"Test Accuracy: %f\" % accuracy(pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/task1_dataset_test.csv')\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Loqwauz9Th9J",
        "outputId": "1074b251-ec34-426e-b6a2-49162905a47b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5f223325-6e33-414e-b920-3ded2447a076\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_1</th>\n",
              "      <th>x_2</th>\n",
              "      <th>x_3</th>\n",
              "      <th>x_4</th>\n",
              "      <th>x_5</th>\n",
              "      <th>x_6</th>\n",
              "      <th>x_7</th>\n",
              "      <th>x_8</th>\n",
              "      <th>x_9</th>\n",
              "      <th>x_10</th>\n",
              "      <th>x_11</th>\n",
              "      <th>x_12</th>\n",
              "      <th>x_13</th>\n",
              "      <th>x_14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>21598</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>969</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>1126</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>9866</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>21599</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f223325-6e33-414e-b920-3ded2447a076')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f223325-6e33-414e-b920-3ded2447a076 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f223325-6e33-414e-b920-3ded2447a076');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   x_1  x_2    x_3  x_4  x_5  x_6  x_7  x_8  x_9  x_10  x_11  x_12  x_13  x_14\n",
              "0   57    2  21598    1    1    6    0    0    0     1     1     0    19     0\n",
              "1   27    2    969    0    0    0    9    0    0     1     1     0    19     0\n",
              "2   25    6   1126    1    1    1    6    1    0     0    12     0     4     0\n",
              "3   50    4   9866    1    1    1    4    1    0     0     1     0     0     0\n",
              "4   23    6  21599    0    0    1    1    1    0     0     1     0     3     0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VUmlgfdHIHBU"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "df_test_scale = min_max_scaler.fit_transform(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QoEBjRj1SD8M",
        "outputId": "ef0c4ebd-78d1-438e-90ee-bca6373ae409"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.27777778, 0.25      , 0.15548456, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.125     , 0.25      , 0.12631384, ..., 0.03296703, 0.04301075,\n",
              "        0.        ],\n",
              "       [0.79166667, 0.625     , 0.11913692, ..., 0.        , 0.29032258,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.55555556, 0.625     , 0.61994721, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.06944444, 0.125     , 0.20924202, ..., 0.        , 0.04301075,\n",
              "        0.        ],\n",
              "       [0.40277778, 0.25      , 0.69912488, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict 5 images from validation set.\n",
        "n_t = 100\n",
        "test_t = df_test_scale[:n_t]\n",
        "predictions = neural_net(test_t)\n",
        "\n",
        "# Display image and model prediction.\n",
        "for i in range(n_t):\n",
        "    print(\"Model prediction: %i\" % np.argmax(predictions.numpy()[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "73tqQwpNUfeM",
        "outputId": "8be7c0f1-8434-4d4d-be15-440c1cd0bcc4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 1\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n",
            "Model prediction: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEMaVW67IHBV"
      },
      "source": [
        "\n",
        " Author: Aymeric Damien \n",
        "\n",
        " License: MIT \n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "task1_Multilayer_Perceptron_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}